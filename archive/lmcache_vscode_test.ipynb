{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMCache Backend Latency Test (GPU + Disk)\n",
    "\n",
    "This Colab-friendly notebook starts an LMCache controller, configures a local Disk tier,\n",
    "runs a small vLLM model, and measures latency for repeated prompts while steering\n",
    "placement between GPU (hot) and Disk (warm) using perplexity/time-variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef59b2e",
   "metadata": {},
   "source": [
    "## 1) Setup\n",
    "\n",
    "- Define repo, config, log, and disk paths.\n",
    "- Install dependencies and optionally unzip your repo into /content/src.\n",
    "- Update LMCache config for GPU + Disk (no CPU/Remote)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef40d789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [1] Setting up environment and paths ===\n",
      "Paths set: /src /src/config.yaml /src/controller.log /srclmcache_warm\n"
     ]
    }
   ],
   "source": [
    "print('=== [1] Setting up environment and paths ===')\n",
    "# Environment and paths\n",
    "import os, sys, textwrap\n",
    "REPO_DIR = '/src'\n",
    "CONFIG   = f'{REPO_DIR}/config.yaml'\n",
    "LOGFILE  = f'{REPO_DIR}/controller.log'\n",
    "DISK_DIR = f'{REPO_DIR}lmcache_warm'\n",
    "os.makedirs(REPO_DIR, exist_ok=True)\n",
    "os.makedirs(DISK_DIR, exist_ok=True)\n",
    "print('Paths set:', REPO_DIR, CONFIG, LOGFILE, DISK_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b517b0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [2] Installing dependencies and checking GPU ===\n",
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "print('=== [2] Installing dependencies and checking GPU ===')\n",
    "# Install dependencies (rerun on fresh runtimes)\n",
    "!pip -q install -U pip\n",
    "!pip -q install requests transformers accelerate safetensors\n",
    "# vLLM provides the LLM runtime; install if not present\n",
    "!pip -q install vllm || true\n",
    "# LMCache CLI (controller); if unavailable from pip in your env, use your script instead\n",
    "!pip -q install lmcache || true\n",
    "import subprocess, json\n",
    "print('GPU available:', subprocess.run(['bash','-lc','nvidia-smi'], capture_output=True).returncode == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed2b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [3] Checking for uploaded repo (src.zip) ===\n",
      "ls: cannot access '//src/src': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "print('=== [3] Checking for uploaded repo (src.zip) ===')\n",
    "# If you uploaded src.zip, unzip it to /content/src\n",
    "from pathlib import Path\n",
    "if Path('src.zip').exists():\n",
    "    !rm -rf /{}/src\n",
    "    !mkdir -p /{REPO_DIR}\n",
    "    !unzip -o src.zip -d /{REPO_DIR} > /dev/null\n",
    "!ls -la /{REPO_DIR}/src || true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f71d25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [4] Writing LMCache config (GPU+Disk only) ===\n",
      "Wrote config to /src/config.yaml\n",
      "local_cpu: false\n",
      "local_disk:\n",
      "  enable: true\n",
      "  eviction_policy: lru\n",
      "  max_disk_size_gb: 50\n",
      "  root_dir: /srclmcache_warm\n",
      "remote_storage:\n",
      "  enable: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('=== [4] Writing LMCache config (GPU+Disk only) ===')\n",
    "# Update config: enable Disk, disable CPU/Remote, set disk root_dir to /content/lmcache_warm\n",
    "import yaml\n",
    "cfg = yaml.safe_load(open(CONFIG)) if os.path.exists(CONFIG) else {}\n",
    "cfg.setdefault('local_disk', {})\n",
    "cfg['local_disk']['enable'] = True\n",
    "cfg['local_disk']['root_dir'] = DISK_DIR\n",
    "cfg['local_disk']['max_disk_size_gb'] = cfg['local_disk'].get('max_disk_size_gb', 50)\n",
    "cfg['local_disk']['eviction_policy'] = 'lru'\n",
    "cfg['local_cpu'] = False\n",
    "cfg.setdefault('remote_storage', {})\n",
    "cfg['remote_storage']['enable'] = False\n",
    "open(CONFIG, 'w').write(yaml.safe_dump(cfg))\n",
    "print('Wrote config to', CONFIG)\n",
    "print(open(CONFIG).read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8ebf0b",
   "metadata": {},
   "source": [
    "## 2) Start LMCache Controller\n",
    "\n",
    "- Tail controller logs for quick diagnostics.\n",
    "- Start via repo script if present, else use lmcache_controller CLI.\n",
    "- Verify health on http://127.0.0.1:9000/healthz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "240e5aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [5] Helper print_last_lines() defined ===\n"
     ]
    }
   ],
   "source": [
    "# Helper to tail last N lines of a file\n",
    "from collections import deque\n",
    "def print_last_lines(path: str, n: int = 80):\n",
    "    if not os.path.exists(path):\n",
    "        print('No log at', path) \n",
    "        return\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            last = deque(f, maxlen=n)\n",
    "        print(f'--- Last {len(last)} lines of {path} ---')\n",
    "        for b in last:\n",
    "            print(b.decode('utf-8', errors='replace').rstrip())\n",
    "    except Exception as e:\n",
    "        print('log read error:', e)\n",
    "print('=== [5] Helper print_last_lines() defined ===')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a090ec8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [6] Starting LMCache controller (script or CLI) ===\n",
      "Starting controller via lmcache_controller CLI\n",
      "--- Last 0 lines of /src/controller.log ---\n"
     ]
    }
   ],
   "source": [
    "print('=== [6] Starting LMCache controller (script or CLI) ===')\n",
    "# Start LMCache controller (prefer repo script; fallback to CLI)\n",
    "import subprocess, time, shutil\n",
    "os.environ['LMCACHE_CONFIG_FILE'] = CONFIG\n",
    "START_SCRIPT = f'{REPO_DIR}/start_controller_server.sh'\n",
    "proc = None\n",
    "if os.path.exists(START_SCRIPT):\n",
    "    print('Starting controller via script:', START_SCRIPT)\n",
    "    os.chmod(START_SCRIPT, 0o755)\n",
    "    proc = subprocess.Popen(['bash', START_SCRIPT], cwd=REPO_DIR, stdout=open(LOGFILE, 'ab'), stderr=subprocess.STDOUT, env=os.environ.copy())\n",
    "elif shutil.which('lmcache_controller'):\n",
    "    print('Starting controller via lmcache_controller CLI')\n",
    "    cmd = ['lmcache_controller','--host','127.0.0.1','--port','9000','--monitor-port','9001','--config', CONFIG]\n",
    "    proc = subprocess.Popen(cmd, stdout=open(LOGFILE, 'ab'), stderr=subprocess.STDOUT, env=os.environ.copy())\n",
    "else:\n",
    "    print('No controller found. Install lmcache or provide start_controller_server.sh in /content/src')\n",
    "time.sleep(1.0)\n",
    "print_last_lines(LOGFILE, 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ed85d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [7] Health check: LMCache controller /healthz ===\n",
      "Error: Controller not reachable; check logs above\n"
     ]
    }
   ],
   "source": [
    "print('=== [7] Health check: LMCache controller /healthz ===')\n",
    "# Health check loop\n",
    "import requests, time\n",
    "ok=False\n",
    "for _ in range(10):\n",
    "    try:\n",
    "        r = requests.get('http://127.0.0.1:9000/healthz', timeout=1.0)\n",
    "        print('health:', r.status_code, r.text)\n",
    "        ok=True\n",
    "        break\n",
    "    except Exception as e:\n",
    "        time.sleep(0.5)\n",
    "if not ok:\n",
    "    print('Error: Controller not reachable; check logs above')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab658a29",
   "metadata": {},
   "source": [
    "## 3) Initialize Model and Cache\n",
    "\n",
    "- Initialize a small model in vLLM (Gemma 270M).\n",
    "- Bind LMCache controller + MultiTierCache manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16ee62d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [8] Initializing vLLM LLM (Gemma 270M) ===\n",
      "INFO 11-21 01:57:30 [utils.py:253] non-default args: {'disable_log_stats': True, 'model': 'google/gemma-3-270m-it'}\n",
      "Failed to init vLLM. Ensure GPU runtime and permissions for the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-3-270m-it.\n401 Client Error. (Request ID: Root=1-691fc714-79bc2e874b76a75e60ca385f;58b7dee3-4a11-46dc-8a19-7f5b1b56c3fa)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-3-270m-it/resolve/main/config.json.\nAccess to model google/gemma-3-270m-it is restricted. You must have access to it and be authenticated to access it. Please log in.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/google/gemma-3-270m-it/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1008\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0;31m# Unauthorized => likely a token issue => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1542\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1544\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1461\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGatedRepoError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-691fc714-79bc2e874b76a75e60ca385f;58b7dee3-4a11-46dc-8a19-7f5b1b56c3fa)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-3-270m-it/resolve/main/config.json.\nAccess to model google/gemma-3-270m-it is restricted. You must have access to it and be authenticated to access it. Please log in.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3189685355.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamplingParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'google/gemma-3-270m-it'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSamplingParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LLM initialized'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/vllm/entrypoints/llm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, runner, convert, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, allowed_media_domains, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, disable_custom_all_reduce, hf_token, hf_overrides, mm_processor_kwargs, pooler_config, override_pooler_config, structured_outputs_config, kv_cache_memory_bytes, compilation_config, logits_processors, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;31m# Create the Engine (autoselects V0 vs V1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         self.llm_engine = LLMEngine.from_engine_args(\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0mengine_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musage_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUsageContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLLM_CLASS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/vllm/v1/engine/llm_engine.py\u001b[0m in \u001b[0;36mfrom_engine_args\u001b[0;34m(cls, engine_args, usage_context, stat_loggers, enable_multiprocessing)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;31m# Create the engine configs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mvllm_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_engine_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musage_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mexecutor_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvllm_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/vllm/engine/arg_utils.py\u001b[0m in \u001b[0;36mcreate_engine_config\u001b[0;34m(self, usage_context, headless)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_cloud_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m             (self.model, self.tokenizer, self.speculative_config) = (\n\u001b[0;32m-> 1351\u001b[0;31m                 maybe_override_with_speculators(\n\u001b[0m\u001b[1;32m   1352\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m                     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/vllm/transformers_utils/config.py\u001b[0m in \u001b[0;36mmaybe_override_with_speculators\u001b[0;34m(model, tokenizer, trust_remote_code, revision, vllm_speculative_config, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mgguf_model_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"local_files_only\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhuggingface_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHF_HUB_OFFLINE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m     config_dict, _ = PretrainedConfig.get_config_dict(\n\u001b[0m\u001b[1;32m    531\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgguf_model_repo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgguf_model_repo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    722\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0mconfiguration_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_raise_exceptions_for_gated_repo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             raise OSError(\n\u001b[0m\u001b[1;32m    544\u001b[0m                 \u001b[0;34m\"You are trying to access a gated repo.\\nMake sure to have access to it at \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0;34mf\"https://huggingface.co/{path_or_repo_id}.\\n{str(e)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-3-270m-it.\n401 Client Error. (Request ID: Root=1-691fc714-79bc2e874b76a75e60ca385f;58b7dee3-4a11-46dc-8a19-7f5b1b56c3fa)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-3-270m-it/resolve/main/config.json.\nAccess to model google/gemma-3-270m-it is restricted. You must have access to it and be authenticated to access it. Please log in."
     ]
    }
   ],
   "source": [
    "print('=== [8] Initializing vLLM LLM (Gemma 270M) ===')\n",
    "# Initialize vLLM LLM (Gemma 270M)\n",
    "from vllm import LLM, SamplingParams\n",
    "try:\n",
    "    llm = LLM(model='google/gemma-3-270m-it')\n",
    "    sp = SamplingParams(max_tokens=64, temperature=0.0)\n",
    "    print('LLM initialized')\n",
    "except Exception as e:\n",
    "    print('Failed to init vLLM. Ensure GPU runtime and permissions for the model.')\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ebad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== [9] Wiring LMCacheController + MultiTierCache ===')\n",
    "# Import LMCache client + manager\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "from src.cache_controller import LMCacheController\n",
    "from src.tiered_caching import MultiTierCache\n",
    "controller = LMCacheController(host='127.0.0.1', port=9000, model='google/gemma-3-270m-it')\n",
    "cache_manager = MultiTierCache(controller)\n",
    "cache_manager.set_llm(llm)\n",
    "print('Cache manager ready')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd3fe8",
   "metadata": {},
   "source": [
    "## 4) Latency Tests (GPU vs Disk)\n",
    "\n",
    "- Use perplexity and time-variance to steer placement.\n",
    "- Run twice to observe warm-cache speedups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d1fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to run a latency test with desired perplexity/time_variance\n",
    "import time as _t\n",
    "def latency_run(label: str, prompt: str, perplexity: float, time_variance: float, max_tokens: int = 64):\n",
    "    meta = {'perplexity': perplexity, 'time_variance': time_variance}\n",
    "    sp_local = SamplingParams(max_tokens=max_tokens, temperature=0.0)\n",
    "    print(f'=== [10] latency_run start: {label} | perplexity={perplexity}, time_variance={time_variance}, max_tokens={max_tokens} ===')\n",
    "    print('Prompt length (chars):', len(prompt))\n",
    "    # First run\n",
    "    t0 = _t.time()\n",
    "    _ = cache_manager.generate_and_manage(prompt, sp_local, metadata=meta.copy())\n",
    "    t1 = _t.time()\n",
    "    tokens = controller.tokenize(prompt)\n",
    "    layout = controller.lookup(tokens)\n",
    "    b1 = layout.get('lmcache_default_instance', [None])[0]\n",
    "    # Second run\n",
    "    t2 = _t.time()\n",
    "    _ = cache_manager.generate_and_manage(prompt, sp_local, metadata=meta.copy())\n",
    "    t3 = _t.time()\n",
    "    layout2 = controller.lookup(tokens)\n",
    "    b2 = layout2.get('lmcache_default_instance', [None])[0]\n",
    "    print(f'[{label}] Run1 backend={b1} latency={t1-t0:.3f}s | Run2 backend={b2} latency={t3-t2:.3f}s')\n",
    "    return {'label': label, 'b1': b1, 't1': t1-t0, 'b2': b2, 't2': t3-t2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e65699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU-preferred test (hot): low perplexity / low variance\n",
    "res_gpu = latency_run('GPU', 'Hello GPU test ' * 128, perplexity=5.0, time_variance=0.1, max_tokens=64)\n",
    "res_gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3886d0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disk-preferred test (warm): high perplexity / high variance\n",
    "res_disk = latency_run('Disk', 'Move to disk test ' * 512, perplexity=100.0, time_variance=0.9, max_tokens=32)\n",
    "res_disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e27d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom test: tweak to steer placement\n",
    "custom_prompt = 'Custom backend placement test ' * 256\n",
    "res_custom = latency_run('Custom', custom_prompt, perplexity=30.0, time_variance=0.5, max_tokens=48)\n",
    "res_custom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d7fdce",
   "metadata": {},
   "source": [
    "## 5) Summary & Inspect Disk\n",
    "\n",
    "- Review timings and backends.\n",
    "- List a few files from the Disk tier directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd2cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== [11] Summary and Disk inspection ===')\n",
    "# Summary\n",
    "from pprint import pprint\n",
    "pprint({'GPU': res_gpu, 'Disk': res_disk, 'Custom': res_custom})\n",
    "print('Disk dir contents (first few files):')\n",
    "!find /{REPO_DIR}/lmcache_warm -type f | head -n 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5946a21b",
   "metadata": {},
   "source": [
    "## 6) TTFT Batch Benchmarks (Long Contexts)\n",
    "\n",
    "Measure approximate TTFT by generating only 1 token.\n",
    "Runs multiple prompts with long shared prefixes, comparing first vs second run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b2b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== [12] Running TTFT batch benchmarks (long-context prompts) ===')\n",
    "import time as _t\n",
    "from pprint import pprint\n",
    "\n",
    "def make_long_context(repeats: int = 2048) -> str:\n",
    "    base = 'In a distant future, advanced neural architectures collaborate with humans to solve complex problems. '\n",
    "    return base * (repeats // 8)\n",
    "\n",
    "base_ctx = make_long_context(2048)\n",
    "prompts = [f'{base_ctx} Task {i}: Write a concise plan.' for i in range(5)]\n",
    "sp_ttft = SamplingParams(max_tokens=1, temperature=0.0)\n",
    "\n",
    "results = []\n",
    "for i, p in enumerate(prompts):\n",
    "    t0 = _t.time()\n",
    "    _ = cache_manager.generate_and_manage(p, sp_ttft, metadata={'perplexity': 12.0, 'time_variance': 0.2})\n",
    "    t1 = _t.time()\n",
    "    tokens = controller.tokenize(p)\n",
    "    layout = controller.lookup(tokens)\n",
    "    b1 = layout.get('lmcache_default_instance', [None])[0]\n",
    "\n",
    "    t2 = _t.time()\n",
    "    _ = cache_manager.generate_and_manage(p, sp_ttft, metadata={'perplexity': 12.0, 'time_variance': 0.2})\n",
    "    t3 = _t.time()\n",
    "    layout2 = controller.lookup(tokens)\n",
    "    b2 = layout2.get('lmcache_default_instance', [None])[0]\n",
    "\n",
    "    results.append({'idx': i, 'ttft_first': t1-t0, 'ttft_second': t3-t2, 'backend_first': b1, 'backend_second': b2})\n",
    "\n",
    "print('TTFT results (seconds):')\n",
    "pprint(results)\n",
    "print('Avg first:', sum(r['ttft_first'] for r in results)/len(results))\n",
    "print('Avg second:', sum(r['ttft_second'] for r in results)/len(results))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
